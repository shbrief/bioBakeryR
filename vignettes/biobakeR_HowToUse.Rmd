---
title: "biobakeR: Run bioBakery workflow on Terra using R"
author: "Sehyun Oh"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: false
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
suppressPackageStartupMessages({
  library(biobakeR)
  library(AnVIL)
  library(SummarizedExperiment)
})
source('~/data2/biobakeR/R/getOutput.R')
dest_dir <- "~/data2/biobakeR/inst/extdata/outputs"
HSM7J4NY_dir <- "~/data2/biobakeR/inst/extdata/outputs/HSM7J4NY"
data_dir <- "~/data2/biobakeR/inst/extdata/outputs/data"
```

# Overview
[bioBakery workflows](https://github.com/biobakery/biobakery_workflows) is a collection 
of workflows and tasks for executing common microbial community analyses using standardized, 
validated tools and parameters. bioBakery is built and maintained by [Huttenhower lab](http://huttenhower.sph.harvard.edu/).

For R users with limited computing resources, we introduce biobakeR workflow
package. This package allows users to run Whole Metagenome Shotgun (wmgx) workflow 
version 3 on Google Cloud without writing any workflow, installing softwares, nor 
managing cloud resources. The computing resource is managed by [Terra](https://app.terra.bio/#), 
a cloud-based genomics platform, and users only need to setup their account only
once at the beginning to use biobakeR.

**0. Pre-requisite**   
You need [Terra account setup](https://support.terra.bio/hc/en-us/articles/360034677651-Account-setup-and-exploring-Terra). 
The email address linked to Terra account and the billing project name are required 
to use biobakeR package.   

**1. Input**   
1-1. `cloneWorkspace` function copies the template workspace containing the bioBakery
workflow. Workspace is the main building block of [Terra](https://app.terra.bio/#), 
where different resources are delivered through. For biobakeR, the 'template' 
workspace is where default workflow is store and users will have their own copy 
of it, where they can modify, compute, and save their own results.   
1-2. `updateInput` function takes user's inputs. There are two required inputs: `ProjectName` 
(string) and `InputRead1Files` (tsv file). You can optionally provide metadata tsv file 
through `InputMetadataFile` argument. You can check the current input information using 
`currentInput` function.

**2. Run workflow**   
`launchWorkflow` function launch the bioBakery workflow in Terra. You can abort 
the submission using `abortSubmission` function. For now, the input files should 
be saved in Google bucket. 

**3. Result**   
3-1. `monitorSubmission` function allows you to monitor the status of your workflow run.   
3-2. `listOutput` function displays the list of your workflow outputs.  
3-3. `tableHead` function allows you to check the head of output tsv files.   
3-4. `getOutput` function allows you to download your outputs.

<br>

Here are the basic input parameters used in this example.

```{r}
accountEmail <- "shbrief@gmail.com"
billingProjectName <- "waldronlab-terra-rstudio"
workspaceName <- "mtx_workflow_biobakery_ver3"
```

# Setup
## Clone Workspace
First, you should clone the template workspace using `cloneWorkspace` function. 
Note that you need to provide a unique name for the cloned workspace through `workspaceName`
argument. "mtx_workflow_biobakery_ver3" already exists, so the below cloning fails. 

```{r}
cloneWorkspace(accountEmail, billingProjectName, workspaceName)
```

With the unique workspace name, you can succesfully clone the workspace.
```{r}
cloneWorkspace(accountEmail, billingProjectName, workspaceName = "test")
```

```{r echo=FALSE, message=FALSE}
## Delete test workspace
terra <- Terra()
resp <- terra$deleteWorkspace(workspaceNamespace = billingProjectName,
                              workspaceName = "test")
rm(resp)
```

## Format of inputs
`input` is a table containing the input files' Google bucket location. This
example input list file contains 6 fastq files. `AnVIL::gsutil_pipe` function 
allows you to read a google bucket object without downloading it. More detail
can be found in [AnVIL vignette](http://www.bioconductor.org/packages/release/bioc/vignettes/AnVIL/inst/doc/Introduction.html).

```{r}
input <- "gs://fc-07ee4ddc-5b5b-46f6-bed7-809aa14bb012/IBDMDB/ibdmdb_file_list.txt"
read.table(gsutil_pipe(input), sep  = "\t")
```

`inputMeta` contains the metadata of the samples and the optional input for biobakeR. 

```{r warning=FALSE}
inputMeta <- "gs://fc-07ee4ddc-5b5b-46f6-bed7-809aa14bb012/IBDMDB/ibdmdb_demo_metadata.txt"
read.table(gsutil_pipe(inputMeta), sep = "\t", header = TRUE)
```


## Prepare Input
### Current input
You can review the current input data.
```{r}
currentInput(accountEmail, billingProjectName, workspaceName)
```

If you want to check additional input information, you can set `inputOnly = FALSE`.
```{r}
config <- currentInput(accountEmail, billingProjectName, workspaceName, inputOnly = FALSE)
names(config)
```

For example, you can check databases used for this version of workflow.
```{r}
db_ind <- grep("versionSpecific", names(config$input))
config$input[db_ind]
```

### Update input
Before launching the workflow, you should provide the correct input information 
using `updateInput` function.

```{r eval=FALSE}
## This function is not available yet.
input <- "gs://fc-07ee4ddc-5b5b-46f6-bed7-809aa14bb012/IBDMDB/ibdmdb_file_list.txt"
inputMeta <- "gs://fc-07ee4ddc-5b5b-46f6-bed7-809aa14bb012/IBDMDB/ibdmdb_demo_metadata.txt"
updateInput(inputPath = input,
            inputMetadataPath = inputMeta,
            billingProjectName, workspaceName)
```



# Run bioBakery workflow
Once you cloned the template workspace and updated the input with your own data, 
you can launch the workflow using `launchWorkflow` function.

```{r}
launchWorkflow(accountEmail, billingProjectName, workspaceName)
```

## Monitor Progress
```{r}
submissions <- monitorSubmission(accountEmail, billingProjectName, workspaceName)
submissions
```

To abort the most recently submitted job:

```{r}
abortSubmission(accountEmail, billingProjectName, workspaceName,
                submissionId = submissions$submissionId[1])
```


# Result
## List Outputs (need to review)
For the demonstration purpose, we aborted the launched workflow above. This workspace
had a successful run with the same input already. To search that, we screened all
the previous submission status and found the one with 'Done' status.

```{r}
jobs <- monitorSubmission(accountEmail, billingProjectName, workspaceName,
                          mostRecentOnly = FALSE)
jobs_succeed <- which(jobs$succeeded == 1)
jobs[jobs_succeed,]
```

To access the output of the submitted job, you need a submission Id.
```{r}
submission_id <- jobs[jobs_succeed,]$submissionId[1]
submission_id
```

You can check all the output files from a specific submission or you can subset
a specific outputs using `keyword` argument.
```{r collapse=TRUE}
listOutput(accountEmail, billingProjectName, workspaceName, submissionId = submission_id)
listOutput(accountEmail, billingProjectName, workspaceName, submissionId = submission_id, 
           keyword = "humann")
```

Using `tableHead` function, you can check the head of output `.tsv` files without 
dowwnloading them. 

```{r warning=FALSE, collapse=TRUE}
tableHead("HSM7J4NY_genefamilies_relab.tsv", n = 6,
          accountEmail, billingProjectName, workspaceName, 
          submissionId = submission_id)   # gene families relative abundance
```


## Get Outputs
Here, we list the example of major output files from bioBakery workflow.

```{r echo=FALSE}
## check the head of downloaded file
.tableHead <- function(fname, dir, n = 3, ...) {
  fpath <- file.path(dir, fname)
  x <- read.csv(fpath, sep = "\t", header = TRUE, ...)
  head(x, n)
}
```

### Sample-specific outputs
`keyword` argument takes a character string containing a regular expression and as
an example here, we check all `.tsv` output of the sample, "HSM7J4NY".

```{r}
listOutput(accountEmail, billingProjectName, workspaceName, submission_id, 
           keyword = "HSM7J4NY.*.tsv")
```

You can download any file using `getOutput` function. Here, we narrow down the 
download to HSM7J4NY sample's `.tsv` output files.

```{r eval=FALSE}
HSM7J4NY_dir <- "~/data2/biobakeR/inst/extdata/outputs/HSM7J4NY"
getOutput(accountEmail, billingProjectName, workspaceName, submission_id, 
          keyword = "HSM7J4NY.*.tsv", dest_dir = HSM7J4NY_dir)
```

#### HSM7J4NY_genefamilies.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_genefamilies.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_pathabundance.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_pathabundance.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_pathcoverage.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_pathcoverage.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_ecs.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_ecs.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_kos.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_kos.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_ecs_relab.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_ecs_relab.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_genefamilies_relab.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_genefamilies_relab.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY_pathabundance_relab.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY_pathabundance_relab.tsv", HSM7J4NY_dir)
```

#### HSM7J4NY.tsv
```{r echo=FALSE}
.tableHead("HSM7J4NY.tsv", HSM7J4NY_dir, skip = 3)
```




### Output files for visualization
```{r echo=FALSE, eval=FALSE}
listOutput(accountEmail, billingProjectName, workspaceName, submission_id, 
           keyword = "visualization")
```

Output files for visualization is saved in `ibdmdb_test_visualizations.zip`.
```{r eval=FALSE}
dest_dir <- "~/data2/biobakeR/inst/extdata/outputs"
getOutput(accountEmail, billingProjectName, workspaceName, submission_id, 
          keyword = "visualization", dest_dir = dest_dir)
unzip(file.path(dest_dir, "ibdmdb_test_visualizations.zip"), exdir = dest_dir)
```

Here are the list of files used for visualization. 
```{r}
list.files(data_dir)
```

#### humann_feature_counts.tsv
This contains the feature counts (pathways, gene families, ecs) for each sample.

```{r echo=FALSE}
.tableHead("humann_feature_counts.tsv", data_dir)
```

#### humann_read_and_species_count_table.tsv
This contains the counts of reads aligning at each step plus the total number of 
species identified for each sample.

```{r echo=FALSE}
.tableHead("humann_read_and_species_count_table.tsv", data_dir)
```

#### kneaddata_read_count_table.tsv
This contains the read counts (split into pairs and orphans) for each step in the 
quality control process for each sample.

```{r echo=FALSE}
.tableHead("kneaddata_read_count_table.tsv", data_dir)
```

#### metaphlan_taxonomic_profiles.tsv
This contains the merged taxonomic profiles for all samples.

```{r echo=FALSE}
.tableHead("metaphlan_taxonomic_profiles.tsv", data_dir)
```

#### microbial_counts_table.tsv
This table includes counts ratios for each step of the quality control process for all samples.

```{r echo=FALSE}
.tableHead("microbial_counts_table.tsv", data_dir)
```

#### pathabundance_relab.tsv
This is a merged table of the pathway abundances for all samples normalized to relative abundance.

```{r echo=FALSE}
.tableHead("pathabundance_relab.tsv", data_dir)
```

#### qc_counts_orphans_table.tsv
This is table with the total number of orphan reads not aligning to each of the reference tables.

```{r echo=FALSE}
.tableHead("qc_counts_orphans_table.tsv", data_dir)
```

#### qc_counts_pairs_table.tsv
This is table with the total number of paired reads not aligning to each of the reference tables.

```{r echo=FALSE}
.tableHead("qc_counts_pairs_table.tsv", data_dir)
```

#### taxa_counts_table.tsv
This table includes the total number of species and genera before and after filtering.

```{r echo=FALSE}
.tableHead("taxa_counts_table.tsv", data_dir)
```

#### top_average_pathways_names.tsv
This table includes the top pathways by average abundance, with their full names, 
including average abundance and variance.

```{r echo=FALSE}
.tableHead("top_average_pathways_names.tsv", data_dir)
```




### Make SummarizedExperiment
#### Taxonomy profile
```{r}
taxo_profile <- read.csv(file.path(data_dir, "metaphlan_taxonomic_profiles.tsv"),
                         sep = "\t", header = TRUE)
taxo_profile <- tibble::column_to_rownames(taxo_profile, var = "X..taxonomy")
meta <- read.table("~/data2/biobakeR/inst/extdata/ibdmdb_demo_metadata.txt", 
                   sep = "\t", header = TRUE)
colData <- DataFrame(meta)
```

```{r}
se <- SummarizedExperiment(assays = list(taxo_profile = taxo_profile),
                           colData = colData)
se
```


#### Pathway abundance
```{r}
path_abun <- read.csv(file.path(data_dir, "pathabundance_relab.tsv"),
                      sep = "\t", header = TRUE)
path_abun <- tibble::column_to_rownames(path_abun, var = "X..Pathway")
colnames(path_abun) <- gsub("_Abundance", "", colnames(path_abun))
```

```{r}
se <- SummarizedExperiment(assays = list(taxo_profile = path_abun),
                           colData = colData)
se
```
